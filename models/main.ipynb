{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample user submission\n",
    "message = '''\n",
    "    Create a count for each character in the string.\n",
    "    For each character:\n",
    "    Convert it to lowercase.\n",
    "    Count how many times it appears.\n",
    "    Set total_length to 0 and odd_count to 0.\n",
    "    For each character count:\n",
    "    Add the even part of the count to total_length.\n",
    "    If the count is odd, add 1 to odd_count.\n",
    "    If odd_count is greater than 0, add 1 to total_length.\n",
    "    Return total_length.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are a professor who specializes in solving code problems.\n",
      "    The user will submit in words their approach to solving the problem.\n",
      "    Analyze the user's submission and provide feedback.\n",
      "\n",
      "    Output your feedback in JSON format with the following structure:\n",
      "    {\n",
      "        \"title\": \"Create a title for this analysis\",\n",
      "        \"analysis\": \"Create a detailed analysis on the user's submission\",\n",
      "        \"summary\": \"Create a concise one-paragraph summary of the analysis\",\n",
      "        \"score\": \"An integer score: 1 (incorrect), 2 (partially correct), 3 (correct)\"\n",
      "    }\n",
      "\n",
      "    Here are the problem details:\n",
      "    Category: \n",
      "    manipulations\n",
      "\n",
      "    Subcategory: \n",
      "    strings\n",
      "\n",
      "    Difficulty:\n",
      "    easy\n",
      "\n",
      "    Title: \n",
      "    Longest Palindrome\n",
      "\n",
      "    Description: \n",
      "    Given a string s which consists of lowercase or uppercase letters, return the length of the longest palindrome that can be built with those letters. Letters are case sensitive, for example, 'Aa' is not considered a palindrome.\n",
      "\n",
      "    Constraints: \n",
      "    1 <= s.length <= 2000\n",
      "s consists of lowercase and/or uppercase English letters only.\n",
      "\n",
      "    Examples:\n",
      "    Input: abccccdd, Output: 7, Explanation: One longest palindrome that can be built is 'dccaccd', whose length is 7.\n",
      "Input: a, Output: 1, Explanation: The longest palindrome that can be built is 'a', whose length is 1.\n",
      "\n",
      "    Here is the user's submission:\n",
      "    \n",
      "    Create a count for each character in the string.\n",
      "    For each character:\n",
      "    Convert it to lowercase.\n",
      "    Count how many times it appears.\n",
      "    Set total_length to 0 and odd_count to 0.\n",
      "    For each character count:\n",
      "    Add the even part of the count to total_length.\n",
      "    If the count is odd, add 1 to odd_count.\n",
      "    If odd_count is greater than 0, add 1 to total_length.\n",
      "    Return total_length.\n",
      "\n",
      "\n",
      "    Ensure your output is coherent and follows the JSON structure provided.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load JSON data\n",
    "import json\n",
    "\n",
    "with open('sample_problem.json', 'r') as file:\n",
    "    problem_data = json.load(file)\n",
    "\n",
    "# Define system_prompt\n",
    "system_prompt = f'''\n",
    "    You are a professor who specializes in solving code problems.\n",
    "    The user will submit in words their approach to solving the problem.\n",
    "    Analyze the user's submission and provide feedback.\n",
    "\n",
    "    Output your feedback in JSON format with the following structure:\n",
    "    {{\n",
    "        \"title\": \"Create a title for this analysis\",\n",
    "        \"analysis\": \"Create a detailed analysis on the user's submission\",\n",
    "        \"summary\": \"Create a concise one-paragraph summary of the analysis\",\n",
    "        \"score\": \"An integer score: 1 (incorrect), 2 (partially correct), 3 (correct)\"\n",
    "    }}\n",
    "\n",
    "    Here are the problem details:\n",
    "    Category: \n",
    "    {problem_data['category']}\n",
    "\n",
    "    Subcategory: \n",
    "    {problem_data['subcategory']}\n",
    "\n",
    "    Difficulty:\n",
    "    {problem_data['difficulty']}\n",
    "\n",
    "    Title: \n",
    "    {problem_data['title']}\n",
    "\n",
    "    Description: \n",
    "    {problem_data['description']}\n",
    "\n",
    "    Constraints: \n",
    "    {chr(10).join([f'{constraint}' for constraint in problem_data['constraints']])}\n",
    "\n",
    "    Examples:\n",
    "    {chr(10).join([f'Input: {example[\"input\"]}, Output: {example[\"output\"]}, Explanation: {example[\"explanation\"]}' for example in problem_data['examples']])}\n",
    "\n",
    "    Here is the user's submission:\n",
    "    {message}\n",
    "\n",
    "    Ensure your output is coherent and follows the JSON structure provided.\n",
    "'''\n",
    "\n",
    "print(system_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face Inference API\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# import requests\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# API_URL = 'https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3.1-8B'\n",
    "# headers = {'Authorization': f'Bearer {os.getenv('HUGGINGFACE_HUB_TOKEN')}'}\n",
    "\n",
    "# def query(payload):\n",
    "# \tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "# \treturn response.json()\n",
    "\t\n",
    "# output = query({\n",
    "# \t'inputs': 'What kind of questions can you answer?',\n",
    "# })\n",
    "\n",
    "# print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Meta-Llama-3.1-8B\n",
    "# import transformers\n",
    "# import torch\n",
    "\n",
    "# model_id = \"meta-llama/Meta-Llama-3.1-8B\"\n",
    "\n",
    "# pipeline = transformers.pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model_id,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "\n",
    "# print(pipeline(\"Hey how are you doing today?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LLaMA-2\n",
    "# from gradio_client import Client\n",
    "\n",
    "# client = Client('huggingface-projects/llama-2-13b-chat')\n",
    "# try:\n",
    "# \tresult = client.predict(\n",
    "# \t\tmessage=message,\n",
    "# \t\tsystem_prompt=system_prompt,\n",
    "# \t\tmax_new_tokens=1024,\n",
    "# \t\ttemperature=0.6,\n",
    "# \t\ttop_p=0.9,\n",
    "# \t\ttop_k=50,\n",
    "# \t\trepetition_penalty=1.2,\n",
    "# \t\tapi_name=\"/chat\"\n",
    "# \t)\n",
    "# except Exception as e:\n",
    "# \tprint(f'An error occurred: {e}')\n",
    "\n",
    "# print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
